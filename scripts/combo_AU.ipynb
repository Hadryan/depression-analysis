{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['302_CLNF_AUs.txt', '303_CLNF_AUs.txt', '304_CLNF_AUs.txt', '372_CLNF_AUs.txt', '374_CLNF_AUs.txt', '375_CLNF_AUs.txt', '376_CLNF_AUs.txt', '377_CLNF_AUs.txt', '379_CLNF_AUs.txt', '380_CLNF_AUs.txt', '381_CLNF_AUs.txt', '382_CLNF_AUs.txt', '383_CLNF_AUs.txt', '385_CLNF_AUs.txt', '386_CLNF_AUs.txt', '388_CLNF_AUs.txt', '389_CLNF_AUs.txt', '390_CLNF_AUs.txt', '391_CLNF_AUs.txt', '392_CLNF_AUs.txt', '393_CLNF_AUs.txt', '395_CLNF_AUs.txt', '397_CLNF_AUs.txt', '400_CLNF_AUs.txt', '401_CLNF_AUs.txt', '402_CLNF_AUs.txt', '403_CLNF_AUs.txt', '404_CLNF_AUs.txt', '406_CLNF_AUs.txt', '409_CLNF_AUs.txt', '412_CLNF_AUs.txt', '413_CLNF_AUs.txt', '414_CLNF_AUs.txt', '415_CLNF_AUs.txt', '416_CLNF_AUs.txt', '417_CLNF_AUs.txt', '418_CLNF_AUs.txt', '419_CLNF_AUs.txt', '420_CLNF_AUs.txt', '422_CLNF_AUs.txt', '423_CLNF_AUs.txt', '425_CLNF_AUs.txt', '426_CLNF_AUs.txt', '427_CLNF_AUs.txt', '428_CLNF_AUs.txt', '429_CLNF_AUs.txt', '430_CLNF_AUs.txt', '433_CLNF_AUs.txt', '434_CLNF_AUs.txt', '436_CLNF_AUs.txt', '437_CLNF_AUs.txt', '439_CLNF_AUs.txt', '440_CLNF_AUs.txt']\n"
     ]
    }
   ],
   "source": [
    "'''calculate all 3 features for each Action unit'''\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "path=\"C://Users//vandi//Documents//daicwoz_dataset//action_units_trial//\"\n",
    "target = pd.read_csv(\"C://Users//vandi//Documents//daicwoz_dataset//au_test.csv\")\n",
    "files=os.listdir(path)\n",
    "print(files)\n",
    "#print(target.participant[1])\n",
    "#df = pd.DataFrame(columns=[\"participant\",\"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\", \"AU23_c\", \"AU28_c\", \"AU45_c\",\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_AU01=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    temp_df_AU01=data.AU01_r[data.AU01_r!=' 0']\n",
    "    ratio_AU01=temp_df_AU01.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU01\n",
    "    \n",
    "    divide_time=(len(data)*0.033)/2\n",
    "    temp_df_AU01=data.timestamp[data.AU01_r!=' 0']\n",
    "    AU01_st=0\n",
    "    AU01_et=0\n",
    "    AU01_t=-1\n",
    "    l_AU01=temp_df_AU01.tolist()\n",
    "   # print(type(l_AU01[1]))\n",
    "    for j in range(1,len(l_AU01)):\n",
    "        #if i[0:3]=='372':\n",
    "           # print(type(l_AU01[j]))\n",
    "        time=float(l_AU01[j])\n",
    "        if time<=divide_time:\n",
    "            AU01_st+=1\n",
    "        else:\n",
    "            AU01_et+=1\n",
    "    if AU01_st>AU01_et:\n",
    "        AU01_t=0\n",
    "    else:\n",
    "        AU01_t=1\n",
    "    #print(AU01_t)\n",
    "    d_newdf[\"portion\"]=AU01_t\n",
    "    \n",
    "    temp_df_AU01=data.frame[data.AU01_r!=' 0']\n",
    "    l_AU01=temp_df_AU01.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU01:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j\n",
    "    mean_AU01=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU01\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    #print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU01 = df_AU01.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.484732</td>\n",
       "      <td>1</td>\n",
       "      <td>17.642019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.518569</td>\n",
       "      <td>1</td>\n",
       "      <td>12.545008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0</td>\n",
       "      <td>13.269877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.631878</td>\n",
       "      <td>1</td>\n",
       "      <td>19.590347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.515661</td>\n",
       "      <td>1</td>\n",
       "      <td>16.260870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.367763</td>\n",
       "      <td>0</td>\n",
       "      <td>14.173913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.314172</td>\n",
       "      <td>1</td>\n",
       "      <td>10.345824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>1</td>\n",
       "      <td>16.405117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.235848</td>\n",
       "      <td>0</td>\n",
       "      <td>5.961312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.644770</td>\n",
       "      <td>1</td>\n",
       "      <td>10.262381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.270791</td>\n",
       "      <td>0</td>\n",
       "      <td>6.640872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.246674</td>\n",
       "      <td>0</td>\n",
       "      <td>8.161981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.574632</td>\n",
       "      <td>1</td>\n",
       "      <td>18.641463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.347813</td>\n",
       "      <td>0</td>\n",
       "      <td>14.532468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.297056</td>\n",
       "      <td>1</td>\n",
       "      <td>7.237089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.403914</td>\n",
       "      <td>1</td>\n",
       "      <td>13.923928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.424925</td>\n",
       "      <td>1</td>\n",
       "      <td>19.754072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.635318</td>\n",
       "      <td>1</td>\n",
       "      <td>24.039295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.446682</td>\n",
       "      <td>1</td>\n",
       "      <td>21.242424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.145943</td>\n",
       "      <td>0</td>\n",
       "      <td>5.420345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.396244</td>\n",
       "      <td>0</td>\n",
       "      <td>13.235714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.589153</td>\n",
       "      <td>1</td>\n",
       "      <td>24.437014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.532343</td>\n",
       "      <td>1</td>\n",
       "      <td>24.234076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.437467</td>\n",
       "      <td>1</td>\n",
       "      <td>15.571610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.518303</td>\n",
       "      <td>1</td>\n",
       "      <td>21.324523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.481760</td>\n",
       "      <td>1</td>\n",
       "      <td>16.654219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.353375</td>\n",
       "      <td>0</td>\n",
       "      <td>11.581749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.549394</td>\n",
       "      <td>1</td>\n",
       "      <td>27.793323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.435794</td>\n",
       "      <td>0</td>\n",
       "      <td>16.042517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.336788</td>\n",
       "      <td>1</td>\n",
       "      <td>9.900285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.310696</td>\n",
       "      <td>1</td>\n",
       "      <td>6.823932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.246464</td>\n",
       "      <td>0</td>\n",
       "      <td>8.334842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.371009</td>\n",
       "      <td>1</td>\n",
       "      <td>13.229469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.486766</td>\n",
       "      <td>0</td>\n",
       "      <td>14.370417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.293133</td>\n",
       "      <td>0</td>\n",
       "      <td>9.065632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.375691</td>\n",
       "      <td>1</td>\n",
       "      <td>11.660047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.381292</td>\n",
       "      <td>0</td>\n",
       "      <td>11.953935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.382788</td>\n",
       "      <td>1</td>\n",
       "      <td>13.836436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.254990</td>\n",
       "      <td>1</td>\n",
       "      <td>7.850291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.518332</td>\n",
       "      <td>1</td>\n",
       "      <td>14.575029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.354898</td>\n",
       "      <td>1</td>\n",
       "      <td>11.100524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>1</td>\n",
       "      <td>10.284722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.449096</td>\n",
       "      <td>1</td>\n",
       "      <td>18.229068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.471076</td>\n",
       "      <td>0</td>\n",
       "      <td>12.642710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.371356</td>\n",
       "      <td>1</td>\n",
       "      <td>11.925191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.422843</td>\n",
       "      <td>1</td>\n",
       "      <td>13.372247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.489382</td>\n",
       "      <td>1</td>\n",
       "      <td>20.998423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.237654</td>\n",
       "      <td>1</td>\n",
       "      <td>6.413019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.565534</td>\n",
       "      <td>1</td>\n",
       "      <td>12.292625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.250363</td>\n",
       "      <td>0</td>\n",
       "      <td>8.303859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.398933</td>\n",
       "      <td>1</td>\n",
       "      <td>9.708691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>1</td>\n",
       "      <td>16.835744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.567681</td>\n",
       "      <td>1</td>\n",
       "      <td>16.395216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.484732       1      17.642019      0\n",
       "1          303        0.518569       1      12.545008      0\n",
       "2          304        0.500021       0      13.269877      0\n",
       "3          372        0.631878       1      19.590347      1\n",
       "4          374        0.515661       1      16.260870      0\n",
       "5          375        0.367763       0      14.173913      0\n",
       "6          376        0.314172       1      10.345824      1\n",
       "7          377        0.563911       1      16.405117      1\n",
       "8          379        0.235848       0       5.961312      0\n",
       "9          380        0.644770       1      10.262381      1\n",
       "10         381        0.270791       0       6.640872      1\n",
       "11         382        0.246674       0       8.161981      0\n",
       "12         383        0.574632       1      18.641463      0\n",
       "13         385        0.347813       0      14.532468      0\n",
       "14         386        0.297056       1       7.237089      1\n",
       "15         388        0.403914       1      13.923928      1\n",
       "16         389        0.424925       1      19.754072      1\n",
       "17         390        0.635318       1      24.039295      0\n",
       "18         391        0.446682       1      21.242424      0\n",
       "19         392        0.145943       0       5.420345      0\n",
       "20         393        0.396244       0      13.235714      0\n",
       "21         395        0.589153       1      24.437014      0\n",
       "22         397        0.532343       1      24.234076      0\n",
       "23         400        0.437467       1      15.571610      0\n",
       "24         401        0.518303       1      21.324523      0\n",
       "25         402        0.481760       1      16.654219      1\n",
       "26         403        0.353375       0      11.581749      0\n",
       "27         404        0.549394       1      27.793323      0\n",
       "28         406        0.435794       0      16.042517      0\n",
       "29         409        0.336788       1       9.900285      1\n",
       "30         412        0.310696       1       6.823932      1\n",
       "31         413        0.246464       0       8.334842      1\n",
       "32         414        0.371009       1      13.229469      1\n",
       "33         415        0.486766       0      14.370417      0\n",
       "34         416        0.293133       0       9.065632      0\n",
       "35         417        0.375691       1      11.660047      0\n",
       "36         418        0.381292       0      11.953935      1\n",
       "37         419        0.382788       1      13.836436      0\n",
       "38         420        0.254990       1       7.850291      0\n",
       "39         422        0.518332       1      14.575029      1\n",
       "40         423        0.354898       1      11.100524      0\n",
       "41         425        0.355030       1      10.284722      0\n",
       "42         426        0.449096       1      18.229068      1\n",
       "43         427        0.471076       0      12.642710      0\n",
       "44         428        0.371356       1      11.925191      0\n",
       "45         429        0.422843       1      13.372247      0\n",
       "46         430        0.489382       1      20.998423      0\n",
       "47         433        0.237654       1       6.413019      1\n",
       "48         434        0.565534       1      12.292625      0\n",
       "49         436        0.250363       0       8.303859      0\n",
       "50         437        0.398933       1       9.708691      0\n",
       "51         439        0.572674       1      16.835744      0\n",
       "52         440        0.567681       1      16.395216      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0]\n",
      "[[9 5]\n",
      " [1 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75        14\n",
      "           1       0.38      0.75      0.50         4\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.64      0.70      0.62        18\n",
      "weighted avg       0.78      0.67      0.69        18\n",
      "\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=20,random_state=101)\n",
    "dtree.fit(x_train, y_train)\n",
    "y_pred = dtree.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_AU02=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    temp_df_AU02=data.AU02_r[data.AU02_r!=' 0']\n",
    "    ratio_AU02=temp_df_AU02.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU02\n",
    "    \n",
    "    divide_time=(len(data)*0.033)/2\n",
    "    temp_df_AU02=data.timestamp[data.AU02_r!=' 0']\n",
    "    AU02_st=0\n",
    "    AU02_et=0\n",
    "    AU02_t=-1\n",
    "    l_AU02=temp_df_AU02.tolist()\n",
    "    for j in range(1,len(l_AU02)):\n",
    "        time=float(l_AU02[j])\n",
    "        if time<=divide_time:\n",
    "            AU02_st+=1\n",
    "        else:\n",
    "            AU02_et+=1\n",
    "    if AU02_st>AU02_et:\n",
    "        AU02_t=0\n",
    "    else:\n",
    "        AU02_t=1\n",
    "    #print(AU02_t)   \n",
    "    d_newdf[\"portion\"]=AU02_t\n",
    "    \n",
    "    temp_df_AU02=data.frame[data.AU02_r!=' 0']\n",
    "    l_AU02=temp_df_AU02.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU02:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU02=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU02\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    #print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU02 = df_AU02.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.530294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.340560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.418275</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.590572</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.479887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.568704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.659163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.383881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.479757</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.112603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.280607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.409665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.417034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.424121</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.161250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.478077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.401423</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.442272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.333320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.304958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.529819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.464977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.348595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.202841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.197316</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.176146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.232520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.415599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.290708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.370012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.380221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.173548</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.438536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.250544</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.275249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.309006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.286829</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.332355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.373795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.436457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.257192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.566039</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.235052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.312265</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.441674</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.530294       0       0.523795      0\n",
       "1          303        0.340560       0       0.167361      0\n",
       "2          304        0.418275       0       0.202128      0\n",
       "3          372        0.590572       1       0.353493      1\n",
       "4          374        0.479887       1       0.352947      0\n",
       "5          375        0.348500       0       0.334273      0\n",
       "6          376        0.404900       1       0.341146      1\n",
       "7          377        0.568704       1       0.326706      1\n",
       "8          379        0.239107       0       0.154790      0\n",
       "9          380        0.659163       1       0.232895      1\n",
       "10         381        0.383881       1       0.287591      1\n",
       "11         382        0.101379       1       0.153672      0\n",
       "12         383        0.479757       1       0.233583      0\n",
       "13         385        0.112603       0       0.116304      0\n",
       "14         386        0.280607       0       0.172574      1\n",
       "15         388        0.328962       0       0.265002      1\n",
       "16         389        0.384398       1       0.436355      1\n",
       "17         390        0.409665       1       0.214525      0\n",
       "18         391        0.417034       1       0.450540      0\n",
       "19         392        0.078691       0       0.104840      0\n",
       "20         393        0.424121       0       0.410655      0\n",
       "21         395        0.161250       0       0.140323      0\n",
       "22         397        0.478077       0       0.403859      0\n",
       "23         400        0.401423       1       0.426843      0\n",
       "24         401        0.442272       0       0.314617      0\n",
       "25         402        0.333320       0       0.251071      1\n",
       "26         403        0.304958       0       0.235416      0\n",
       "27         404        0.529819       1       0.559436      0\n",
       "28         406        0.464977       1       0.348595      0\n",
       "29         409        0.202841       1       0.170160      1\n",
       "30         412        0.197316       1       0.160503      1\n",
       "31         413        0.176146       0       0.138800      1\n",
       "32         414        0.232520       0       0.223345      1\n",
       "33         415        0.415599       0       0.272425      0\n",
       "34         416        0.290708       1       0.248787      0\n",
       "35         417        0.370012       1       0.317459      0\n",
       "36         418        0.380221       0       0.349086      1\n",
       "37         419        0.355682       0       0.315852      0\n",
       "38         420        0.173548       0       0.146644      0\n",
       "39         422        0.438536       1       0.300341      1\n",
       "40         423        0.250544       1       0.209093      0\n",
       "41         425        0.275249       0       0.159140      0\n",
       "42         426        0.309006       1       0.264633      1\n",
       "43         427        0.286829       1       0.174051      0\n",
       "44         428        0.332355       0       0.323783      0\n",
       "45         429        0.373795       0       0.312888      0\n",
       "46         430        0.436457       0       0.508054      0\n",
       "47         433        0.257192       0       0.181720      1\n",
       "48         434        0.566039       1       0.321428      0\n",
       "49         436        0.235052       1       0.164688      0\n",
       "50         437        0.312265       1       0.214150      0\n",
       "51         439        0.441674       1       0.243719      0\n",
       "52         440        0.506918       1       0.332131      1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_AU04=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    #print(i[0:3])\n",
    "    #print(data)\n",
    "    temp_df_AU04=data.AU04_r[data.AU04_r!=' 0']\n",
    "    ratio_AU04=temp_df_AU04.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU04\n",
    "    \n",
    "    temp_df_AU04=data.timestamp[data.AU04_r!=' 0']\n",
    "    AU04_st=0\n",
    "    AU04_et=0\n",
    "    AU04_t=-1\n",
    "    l_AU04=temp_df_AU04.tolist()\n",
    "    for j in range(1,len(l_AU04)):\n",
    "        time=float(l_AU04[j])\n",
    "        if time<=divide_time:\n",
    "            AU04_st+=1\n",
    "        else:\n",
    "            AU04_et+=1\n",
    "    if AU04_st>AU04_et:\n",
    "        AU04_t=0\n",
    "    else:\n",
    "        AU04_t=1\n",
    "    #print(AU04_t) \n",
    "    d_newdf[\"portion\"]=AU04_t\n",
    "    \n",
    "    temp_df_AU04=data.frame[data.AU04_r!=' 0']\n",
    "    l_AU04=temp_df_AU04.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU04:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU04=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU04\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    #print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU04 = df_AU04.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.584078</td>\n",
       "      <td>0</td>\n",
       "      <td>1.021703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.564669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.357891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.609353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.577345</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.483447</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.470087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.644259</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.209506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.639820</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.482161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.197460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.464005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.415672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.360042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.365305</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.584832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.397922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.215738</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.445914</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.393493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.542238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.434762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.480341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.377360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.283241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.354666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.202002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.119604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.567281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.348834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.450754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.451241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.322766</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.186099</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.776424</td>\n",
       "      <td>0</td>\n",
       "      <td>1.390906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.299240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.381152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.440576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.395488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.412912</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.555958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.514029</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.200906</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.532610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.336354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.645037</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.641384</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.584078       0       1.021703      0\n",
       "1          303        0.564669       0       0.535801      0\n",
       "2          304        0.357891       0       0.187950      0\n",
       "3          372        0.609353       1       0.347216      1\n",
       "4          374        0.577345       1       0.510489      0\n",
       "5          375        0.483447       0       0.581342      0\n",
       "6          376        0.470087       0       0.521016      1\n",
       "7          377        0.644259       1       0.651899      1\n",
       "8          379        0.209506       0       0.188226      0\n",
       "9          380        0.639820       1       0.309110      1\n",
       "10         381        0.482161       0       0.380214      1\n",
       "11         382        0.197460       0       0.176628      0\n",
       "12         383        0.464005       1       0.269797      0\n",
       "13         385        0.415672       0       0.320086      0\n",
       "14         386        0.449400       0       0.299524      1\n",
       "15         388        0.360042       0       0.391810      1\n",
       "16         389        0.365305       0       0.434119      1\n",
       "17         390        0.584832       1       0.390993      0\n",
       "18         391        0.397922       0       0.446490      0\n",
       "19         392        0.215738       0       0.246159      0\n",
       "20         393        0.445914       0       0.465090      0\n",
       "21         395        0.393493       0       0.357750      0\n",
       "22         397        0.542238       0       0.614283      0\n",
       "23         400        0.434762       0       0.496138      0\n",
       "24         401        0.480341       0       0.462277      0\n",
       "25         402        0.377360       0       0.286752      1\n",
       "26         403        0.283241       0       0.258359      0\n",
       "27         404        0.530556       0       0.514688      0\n",
       "28         406        0.354666       0       0.253915      0\n",
       "29         409        0.202002       0       0.192218      1\n",
       "30         412        0.224232       0       0.183330      1\n",
       "31         413        0.119604       0       0.152817      1\n",
       "32         414        0.284055       0       0.257701      1\n",
       "33         415        0.567281       0       0.683991      0\n",
       "34         416        0.348834       0       0.355505      0\n",
       "35         417        0.450754       0       0.464714      0\n",
       "36         418        0.451241       0       0.526038      1\n",
       "37         419        0.322766       0       0.253704      0\n",
       "38         420        0.186099       0       0.166961      0\n",
       "39         422        0.776424       0       1.390906      1\n",
       "40         423        0.299240       0       0.266685      0\n",
       "41         425        0.381152       0       0.211301      0\n",
       "42         426        0.440576       0       0.415177      1\n",
       "43         427        0.395488       0       0.239981      0\n",
       "44         428        0.412912       0       0.382427      0\n",
       "45         429        0.555958       0       0.732747      0\n",
       "46         430        0.514029       0       0.595104      0\n",
       "47         433        0.200906       0       0.189593      1\n",
       "48         434        0.509596       1       0.283571      0\n",
       "49         436        0.532610       0       0.752427      0\n",
       "50         437        0.336354       0       0.265052      0\n",
       "51         439        0.645037       1       0.796319      0\n",
       "52         440        0.641384       1       0.715451      1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU05=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU05=data.AU05_r[data.AU05_r!=' 0']\n",
    "    ratio_AU05=temp_df_AU05.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU05\n",
    "    \n",
    "    temp_df_AU05=data.timestamp[data.AU05_r!=' 0']\n",
    "    AU05_st=0\n",
    "    AU05_et=0\n",
    "    AU05_t=-1\n",
    "    l_AU05=temp_df_AU05.tolist()\n",
    "    for j in range(1,len(l_AU05)):\n",
    "        time=float(l_AU05[j])\n",
    "        if time<=divide_time:\n",
    "            AU05_st+=1\n",
    "        else:\n",
    "            AU05_et+=1\n",
    "    if AU05_st>AU05_et:\n",
    "        AU05_t=0\n",
    "    else:\n",
    "        AU05_t=1\n",
    "    print(AU05_t) \n",
    "    d_newdf[\"portion\"]=AU05_t\n",
    "    \n",
    "    temp_df_AU05=data.frame[data.AU05_r!=' 0']\n",
    "    l_AU05=temp_df_AU05.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU05:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU05=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU05\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU05 = df_AU05.append(d_newdf, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.325670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.342745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.323683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.362516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.605676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.299780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.136223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.373708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.182166</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.660061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.063043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.301960</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.080260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.155675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.260269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.184064</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.278656</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.280350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.235189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.327209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.206720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.086016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.291471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.324606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.081388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.266735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.072715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.095784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.298430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.254579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.083613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.495180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.389363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.180127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.085063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.163237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.349455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.240061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.294288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.359764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.093123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.078317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.526340</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.153052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.348944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.452613</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.325670       0       0.342745      0\n",
       "1          303        0.323683       0       0.211483      0\n",
       "2          304        0.362516       0       0.219898      0\n",
       "3          372        0.605676       1       0.426303      1\n",
       "4          374        0.303505       1       0.191433      0\n",
       "5          375        0.299780       0       0.317710      0\n",
       "6          376        0.136223       0       0.196665      1\n",
       "7          377        0.373708       1       0.255048      1\n",
       "8          379        0.182166       0       0.181915      0\n",
       "9          380        0.660061       1       0.316387      1\n",
       "10         381        0.027538       0       0.121278      1\n",
       "11         382        0.063043       0       0.136289      0\n",
       "12         383        0.301960       1       0.147206      0\n",
       "13         385        0.094581       0       0.184970      0\n",
       "14         386        0.080260       0       0.138944      1\n",
       "15         388        0.234200       0       0.257250      1\n",
       "16         389        0.155675       0       0.212778      1\n",
       "17         390        0.260269       1       0.119087      0\n",
       "18         391        0.184064       0       0.256948      0\n",
       "19         392        0.034313       0       0.153692      0\n",
       "20         393        0.278656       0       0.391903      0\n",
       "21         395        0.354286       0       0.338599      0\n",
       "22         397        0.280350       0       0.195007      0\n",
       "23         400        0.235189       0       0.249463      0\n",
       "24         401        0.327209       0       0.281007      0\n",
       "25         402        0.206720       0       0.290366      1\n",
       "26         403        0.086016       0       0.157015      0\n",
       "27         404        0.291471       0       0.226005      0\n",
       "28         406        0.324606       0       0.261912      0\n",
       "29         409        0.081388       1       0.137182      1\n",
       "30         412        0.046636       0       0.164588      1\n",
       "31         413        0.121711       0       0.177760      1\n",
       "32         414        0.155013       0       0.191668      1\n",
       "33         415        0.266735       0       0.238249      0\n",
       "34         416        0.072715       0       0.180733      0\n",
       "35         417        0.095784       0       0.171061      0\n",
       "36         418        0.298430       0       0.266213      1\n",
       "37         419        0.254579       0       0.225822      0\n",
       "38         420        0.083613       0       0.116094      0\n",
       "39         422        0.495180       1       0.389363      1\n",
       "40         423        0.180127       0       0.247569      0\n",
       "41         425        0.085063       1       0.120287      0\n",
       "42         426        0.163237       0       0.168949      1\n",
       "43         427        0.349455       0       0.328133      0\n",
       "44         428        0.240061       0       0.263426      0\n",
       "45         429        0.294288       0       0.359764      0\n",
       "46         430        0.093123       0       0.158500      0\n",
       "47         433        0.078317       0       0.184545      1\n",
       "48         434        0.526340       1       0.329248      0\n",
       "49         436        0.057321       0       0.130782      0\n",
       "50         437        0.153052       0       0.172343      0\n",
       "51         439        0.348944       1       0.193585      0\n",
       "52         440        0.452613       1       0.264833      1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU06=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU06=data.AU06_r[data.AU06_r!=' 0']\n",
    "    ratio_AU06=temp_df_AU06.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU06\n",
    "    \n",
    "    temp_df_AU06=data.timestamp[data.AU06_r!=' 0']\n",
    "    AU06_st=0\n",
    "    AU06_et=0\n",
    "    AU06_t=-1\n",
    "    l_AU06=temp_df_AU06.tolist()\n",
    "    for j in range(1,len(l_AU06)):\n",
    "        time=float(l_AU06[j])\n",
    "        if time<=divide_time:\n",
    "            AU06_st+=1\n",
    "        else:\n",
    "            AU06_et+=1\n",
    "    if AU06_st>AU06_et:\n",
    "        AU06_t=0\n",
    "    else:\n",
    "        AU06_t=1\n",
    "    print(AU06_t) \n",
    "    d_newdf[\"portion\"]=AU06_t\n",
    "    \n",
    "    temp_df_AU06=data.frame[data.AU06_r!=' 0']\n",
    "    l_AU06=temp_df_AU06.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU06:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU06=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU06\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU06 = df_AU06.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.180344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.240073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.194231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.529207</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.347795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.325911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.250772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.345704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.095290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.218196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.606035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.206995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.073355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.467851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.100298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.263195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.383422</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.235051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.263193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.224640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.206181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.276858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.207167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.460804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.241665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.196018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.344120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.234244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.372454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.226486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.222534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.280591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.044070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.367589</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.452826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.787307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.162407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.213832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.211438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.160713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.274750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.330868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.109857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.197860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.402282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.241101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.334296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.729736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.239043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.392811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.835244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.171932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.430880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.072936</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.509263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.180344       0       0.241180      0\n",
       "1          303        0.240073       0       0.364660      0\n",
       "2          304        0.194231       0       0.297585      0\n",
       "3          372        0.529207       1       0.500273      1\n",
       "4          374        0.347795       1       0.432197      0\n",
       "5          375        0.325911       0       0.639269      0\n",
       "6          376        0.250772       0       0.392894      1\n",
       "7          377        0.345704       1       0.501900      1\n",
       "8          379        0.095290       0       0.218196      0\n",
       "9          380        0.606035       1       0.396803      1\n",
       "10         381        0.206995       0       0.502325      1\n",
       "11         382        0.073355       0       0.201902      0\n",
       "12         383        0.467851       1       0.882311      0\n",
       "13         385        0.100298       0       0.237659      0\n",
       "14         386        0.263195       0       0.547000      1\n",
       "15         388        0.383422       0       0.569339      1\n",
       "16         389        0.235051       0       0.534361      1\n",
       "17         390        0.263193       1       0.269435      0\n",
       "18         391        0.224640       0       0.394871      0\n",
       "19         392        0.206181       0       0.422025      0\n",
       "20         393        0.276858       0       0.407886      0\n",
       "21         395        0.207167       0       0.360326      0\n",
       "22         397        0.460804       0       0.900087      0\n",
       "23         400        0.241665       0       0.483643      0\n",
       "24         401        0.196018       0       0.476976      0\n",
       "25         402        0.344120       0       0.596288      1\n",
       "26         403        0.234244       0       0.401655      0\n",
       "27         404        0.372454       0       0.681367      0\n",
       "28         406        0.226486       0       0.457059      0\n",
       "29         409        0.222534       0       0.420322      1\n",
       "30         412        0.280591       0       0.691657      1\n",
       "31         413        0.044070       0       0.221354      1\n",
       "32         414        0.367589       0       0.759701      1\n",
       "33         415        0.452826       0       0.787307      0\n",
       "34         416        0.162407       0       0.513456      0\n",
       "35         417        0.213832       0       0.444327      0\n",
       "36         418        0.211438       0       0.330287      1\n",
       "37         419        0.204266       0       0.408772      0\n",
       "38         420        0.160713       0       0.376067      0\n",
       "39         422        0.274750       1       0.288035      1\n",
       "40         423        0.330868       0       0.676637      0\n",
       "41         425        0.109857       1       0.324612      0\n",
       "42         426        0.197860       0       0.402282      1\n",
       "43         427        0.241101       0       0.311092      0\n",
       "44         428        0.334296       0       0.729736      0\n",
       "45         429        0.239043       0       0.430694      0\n",
       "46         430        0.392811       0       0.835244      0\n",
       "47         433        0.171932       0       0.288873      1\n",
       "48         434        0.430880       1       0.319416      0\n",
       "49         436        0.101754       0       0.467797      0\n",
       "50         437        0.072936       0       0.413838      0\n",
       "51         439        0.509263       1       0.636812      0\n",
       "52         440        0.493671       1       0.517337      1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU09=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU09=data.AU09_r[data.AU09_r!=' 0']\n",
    "    ratio_AU09=temp_df_AU09.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU09\n",
    "    \n",
    "    temp_df_AU09=data.timestamp[data.AU09_r!=' 0']\n",
    "    AU09_st=0\n",
    "    AU09_et=0\n",
    "    AU09_t=-1\n",
    "    l_AU09=temp_df_AU09.tolist()\n",
    "    for j in range(1,len(l_AU09)):\n",
    "        time=float(l_AU09[j])\n",
    "        if time<=divide_time:\n",
    "            AU09_st+=1\n",
    "        else:\n",
    "            AU09_et+=1\n",
    "    if AU09_st>AU09_et:\n",
    "        AU09_t=0\n",
    "    else:\n",
    "        AU09_t=1\n",
    "    print(AU09_t) \n",
    "    d_newdf[\"portion\"]=AU09_t\n",
    "    \n",
    "    temp_df_AU09=data.frame[data.AU09_r!=' 0']\n",
    "    l_AU09=temp_df_AU09.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU09:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU09=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"AU09_r\"]=mean_AU09\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU09 = df_AU09.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "      <th>AU09_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.495889</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.401948</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.421765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.584143</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.444761</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.437946</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.261560</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.545895</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.568516</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.677844</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.309834</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.213647</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.352594</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.402651</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.473197</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.213552</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.328220</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.314217</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.361573</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.445590</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.393280</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.334596</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.466820</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.417740</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.305956</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.491871</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.143612</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.372499</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.560750</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.203595</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.459592</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.351183</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.315962</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.414193</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.360989</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.360283</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.322389</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.368801</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.383661</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.360646</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.275357</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.574675</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.340198</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.327566</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.555446</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.541778</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target    AU09_r\n",
       "0          302        0.495889       0            NaN      0  0.436690\n",
       "1          303        0.401948       0            NaN      0  0.172582\n",
       "2          304        0.421765       0            NaN      0  0.192734\n",
       "3          372        0.584143       1            NaN      1  0.249341\n",
       "4          374        0.444761       1            NaN      0  0.199676\n",
       "5          375        0.437946       0            NaN      0  0.394839\n",
       "6          376        0.261560       0            NaN      1  0.165308\n",
       "7          377        0.545895       1            NaN      1  0.259160\n",
       "8          379        0.568516       0            NaN      0  0.900911\n",
       "9          380        0.677844       1            NaN      1  0.255370\n",
       "10         381        0.309834       0            NaN      1  0.186398\n",
       "11         382        0.285293       0            NaN      0  0.181410\n",
       "12         383        0.509677       1            NaN      0  0.232121\n",
       "13         385        0.213647       0            NaN      0  0.134786\n",
       "14         386        0.352594       0            NaN      1  0.214783\n",
       "15         388        0.447385       0            NaN      1  0.369057\n",
       "16         389        0.402651       0            NaN      1  0.451719\n",
       "17         390        0.473197       1            NaN      0  0.201126\n",
       "18         391        0.343085       0            NaN      0  0.259875\n",
       "19         392        0.213552       0            NaN      0  0.158725\n",
       "20         393        0.328220       0            NaN      0  0.208625\n",
       "21         395        0.314217       0            NaN      0  0.160611\n",
       "22         397        0.409441       0            NaN      0  0.298812\n",
       "23         400        0.361573       0            NaN      0  0.266518\n",
       "24         401        0.445590       0            NaN      0  0.293684\n",
       "25         402        0.393280       0            NaN      1  0.283679\n",
       "26         403        0.334596       0            NaN      0  0.203720\n",
       "27         404        0.466820       0            NaN      0  0.295510\n",
       "28         406        0.417740       0            NaN      0  0.268876\n",
       "29         409        0.305956       0            NaN      1  0.172160\n",
       "30         412        0.491871       0            NaN      1  0.484422\n",
       "31         413        0.143612       0            NaN      1  0.113038\n",
       "32         414        0.372499       0            NaN      1  0.267675\n",
       "33         415        0.560750       0            NaN      0  0.430311\n",
       "34         416        0.203595       0            NaN      0  0.162630\n",
       "35         417        0.459592       0            NaN      0  0.411337\n",
       "36         418        0.351183       0            NaN      1  0.288769\n",
       "37         419        0.315962       0            NaN      0  0.185353\n",
       "38         420        0.414193       0            NaN      0  0.292816\n",
       "39         422        0.573676       1            NaN      1  0.383922\n",
       "40         423        0.360989       0            NaN      0  0.225664\n",
       "41         425        0.360283       0            NaN      0  0.171267\n",
       "42         426        0.322389       0            NaN      1  0.204161\n",
       "43         427        0.368801       0            NaN      0  0.184261\n",
       "44         428        0.383661       0            NaN      0  0.307709\n",
       "45         429        0.469245       0            NaN      0  0.330687\n",
       "46         430        0.360646       0            NaN      0  0.216627\n",
       "47         433        0.275357       0            NaN      1  0.166433\n",
       "48         434        0.574675       1            NaN      0  0.300206\n",
       "49         436        0.340198       0            NaN      0  0.265932\n",
       "50         437        0.327566       0            NaN      0  0.185320\n",
       "51         439        0.555446       1            NaN      0  0.343468\n",
       "52         440        0.541778       1            NaN      1  0.232959"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU10=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU10=data.AU10_r[data.AU10_r!=' 0']\n",
    "    ratio_AU10=temp_df_AU10.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU10\n",
    "    \n",
    "    temp_df_AU10=data.timestamp[data.AU10_r!=' 0']\n",
    "    AU10_st=0\n",
    "    AU10_et=0\n",
    "    AU10_t=-1\n",
    "    l_AU10=temp_df_AU10.tolist()\n",
    "    for j in range(1,len(l_AU10)):\n",
    "        time=float(l_AU10[j])\n",
    "        if time<=divide_time:\n",
    "            AU10_st+=1\n",
    "        else:\n",
    "            AU10_et+=1\n",
    "    if AU10_st>AU10_et:\n",
    "        AU10_t=0\n",
    "    else:\n",
    "        AU10_t=1\n",
    "    print(AU10_t) \n",
    "    d_newdf[\"portion\"]=AU10_t\n",
    "    \n",
    "    temp_df_AU10=data.frame[data.AU10_r!=' 0']\n",
    "    l_AU10=temp_df_AU10.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU10:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU10=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU10\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU10 = df_AU10.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.205075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.363695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.295614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.568179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.439817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.264745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.089836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.684692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.246405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.117756</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.523238</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.099428</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.264638</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.426171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.176201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.346280</td>\n",
       "      <td>1</td>\n",
       "      <td>0.331995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.297658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.221126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.385506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.430699</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.196375</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.369440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.312609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.440966</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.233781</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.203680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.252314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.061457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.411709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.441513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.245207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.319055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.209816</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.219884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.439238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.120277</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.248979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.319748</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.380254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.715451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.267066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.434843</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.275108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.489217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.199632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.092985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.490063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.501214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.205075       0       0.249146      0\n",
       "1          303        0.363695       0       0.408466      0\n",
       "2          304        0.295614       0       0.308059      0\n",
       "3          372        0.568179       1       0.518656      1\n",
       "4          374        0.439817       1       0.409318      0\n",
       "5          375        0.363095       0       0.745645      0\n",
       "6          376        0.264745       0       0.351353      1\n",
       "7          377        0.416667       1       0.414459      1\n",
       "8          379        0.089836       0       0.247408      0\n",
       "9          380        0.684692       1       0.544694      1\n",
       "10         381        0.246405       0       0.437829      1\n",
       "11         382        0.117756       0       0.220177      0\n",
       "12         383        0.523238       1       0.780088      0\n",
       "13         385        0.099428       0       0.245476      0\n",
       "14         386        0.264638       0       0.485294      1\n",
       "15         388        0.426171       0       0.552113      1\n",
       "16         389        0.176201       0       0.339043      1\n",
       "17         390        0.346280       1       0.331995      0\n",
       "18         391        0.297658       0       0.521521      0\n",
       "19         392        0.221126       0       0.458204      0\n",
       "20         393        0.385506       0       0.519162      0\n",
       "21         395        0.243787       0       0.352850      0\n",
       "22         397        0.430699       0       0.701891      0\n",
       "23         400        0.327166       0       0.496298      0\n",
       "24         401        0.196375       0       0.378263      0\n",
       "25         402        0.369440       0       0.576187      1\n",
       "26         403        0.312609       0       0.465346      0\n",
       "27         404        0.440966       0       0.750193      0\n",
       "28         406        0.233781       0       0.363072      0\n",
       "29         409        0.203680       0       0.417536      1\n",
       "30         412        0.252314       0       0.465228      1\n",
       "31         413        0.061457       0       0.305167      1\n",
       "32         414        0.411709       0       0.759125      1\n",
       "33         415        0.441513       0       0.647680      0\n",
       "34         416        0.245207       0       0.531937      0\n",
       "35         417        0.319055       0       0.472814      0\n",
       "36         418        0.209816       0       0.313317      1\n",
       "37         419        0.303126       0       0.473749      0\n",
       "38         420        0.219884       0       0.363547      0\n",
       "39         422        0.352747       1       0.302610      1\n",
       "40         423        0.439238       0       0.850739      0\n",
       "41         425        0.120277       1       0.319932      0\n",
       "42         426        0.248979       0       0.372830      1\n",
       "43         427        0.319748       0       0.372305      0\n",
       "44         428        0.380254       0       0.715451      0\n",
       "45         429        0.267066       0       0.418091      0\n",
       "46         430        0.434843       0       0.798141      0\n",
       "47         433        0.275108       0       0.405912      1\n",
       "48         434        0.489217       1       0.353117      0\n",
       "49         436        0.199632       0       0.476821      0\n",
       "50         437        0.092985       0       0.404720      0\n",
       "51         439        0.490063       1       0.572880      0\n",
       "52         440        0.501214       1       0.448327      1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU12=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU12=data.AU12_r[data.AU12_r!=' 0']\n",
    "    ratio_AU12=temp_df_AU12.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU12\n",
    "    \n",
    "    temp_df_AU12=data.timestamp[data.AU12_r!=' 0']\n",
    "    AU12_st=0\n",
    "    AU12_et=0\n",
    "    AU12_t=-1\n",
    "    l_AU12=temp_df_AU12.tolist()\n",
    "    for j in range(1,len(l_AU12)):\n",
    "        time=float(l_AU12[j])\n",
    "        if time<=divide_time:\n",
    "            AU12_st+=1\n",
    "        else:\n",
    "            AU12_et+=1\n",
    "    if AU12_st>AU12_et:\n",
    "        AU12_t=0\n",
    "    else:\n",
    "        AU12_t=1\n",
    "    print(AU12_t) \n",
    "    d_newdf[\"portion\"]=AU12_t\n",
    "    \n",
    "    temp_df_AU12=data.frame[data.AU12_r!=' 0']\n",
    "    l_AU12=temp_df_AU12.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU12:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU12=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU12\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU12 = df_AU12.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.213975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.388960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.299735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.540833</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.465133</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.268337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.275274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.368112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.585099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.329937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.618332</td>\n",
       "      <td>1</td>\n",
       "      <td>1.040401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.110055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.438498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.773127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.417348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.251941</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.261866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.158728</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.247458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.350119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.150343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.409196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.458317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.510240</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.352718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.217482</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.297078</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.352120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.083760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.437138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.465377</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.393705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.240996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.267745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.226112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.435215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.408099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.353359</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.157368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.190080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.269432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.376325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.326278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.412213</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.181826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.504520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.356172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.171767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.546279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.213975       0       0.273293      0\n",
       "1          303        0.388960       0       0.319326      0\n",
       "2          304        0.299735       0       0.269551      0\n",
       "3          372        0.540833       1       0.445182      1\n",
       "4          374        0.465133       0       0.445795      0\n",
       "5          375        0.268337       0       0.460795      0\n",
       "6          376        0.275274       0       0.353939      1\n",
       "7          377        0.368112       1       0.369678      1\n",
       "8          379        0.090700       0       0.227083      0\n",
       "9          380        0.585099       1       0.211113      1\n",
       "10         381        0.329937       0       0.412261      1\n",
       "11         382        0.065551       0       0.177030      0\n",
       "12         383        0.618332       1       1.040401      0\n",
       "13         385        0.110055       0       0.274371      0\n",
       "14         386        0.438498       0       0.773127      1\n",
       "15         388        0.417348       0       0.652722      1\n",
       "16         389        0.251941       0       0.390936      1\n",
       "17         390        0.261866       1       0.208413      0\n",
       "18         391        0.158728       0       0.279850      0\n",
       "19         392        0.247458       0       0.323746      0\n",
       "20         393        0.350119       0       0.461580      0\n",
       "21         395        0.150343       0       0.250913      0\n",
       "22         397        0.409196       0       0.459955      0\n",
       "23         400        0.458317       0       0.688463      0\n",
       "24         401        0.375339       0       0.435923      0\n",
       "25         402        0.510240       0       1.228085      1\n",
       "26         403        0.352718       0       0.408045      0\n",
       "27         404        0.364464       0       0.425131      0\n",
       "28         406        0.217482       0       0.273121      0\n",
       "29         409        0.297078       0       0.361582      1\n",
       "30         412        0.352120       0       0.788082      1\n",
       "31         413        0.083760       0       0.170546      1\n",
       "32         414        0.437138       0       0.776644      1\n",
       "33         415        0.465377       0       0.558687      0\n",
       "34         416        0.299600       0       0.430052      0\n",
       "35         417        0.393705       0       0.553437      0\n",
       "36         418        0.240996       0       0.256174      1\n",
       "37         419        0.267745       0       0.409708      0\n",
       "38         420        0.226112       0       0.303017      0\n",
       "39         422        0.435215       1       0.408099      1\n",
       "40         423        0.353359       0       0.505537      0\n",
       "41         425        0.157368       0       0.262093      0\n",
       "42         426        0.190080       0       0.276995      1\n",
       "43         427        0.269432       0       0.275878      0\n",
       "44         428        0.376325       0       0.608297      0\n",
       "45         429        0.326278       0       0.463633      0\n",
       "46         430        0.412213       0       0.611400      0\n",
       "47         433        0.181826       0       0.250456      1\n",
       "48         434        0.504520       1       0.356172      0\n",
       "49         436        0.142698       0       0.349349      0\n",
       "50         437        0.171767       0       0.227414      0\n",
       "51         439        0.561751       1       0.835965      0\n",
       "52         440        0.546279       1       0.667322      1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "df_AU14=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU14=data.AU14_r[data.AU14_r!=' 0']\n",
    "    ratio_AU14=temp_df_AU14.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU14\n",
    "    \n",
    "    temp_df_AU14=data.timestamp[data.AU14_r!=' 0']\n",
    "    AU14_st=0\n",
    "    AU14_et=0\n",
    "    AU14_t=-1\n",
    "    l_AU14=temp_df_AU14.tolist()\n",
    "    for j in range(1,len(l_AU14)):\n",
    "        time=float(l_AU14[j])\n",
    "        if time<=divide_time:\n",
    "            AU14_st+=1\n",
    "        else:\n",
    "            AU14_et+=1\n",
    "    if AU14_st>AU14_et:\n",
    "        AU14_t=0\n",
    "    else:\n",
    "        AU14_t=1\n",
    "    print(AU14_t) \n",
    "    d_newdf[\"portion\"]=AU14_t\n",
    "    \n",
    "    temp_df_AU14=data.frame[data.AU14_r!=' 0']\n",
    "    l_AU14=temp_df_AU14.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU14:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU14=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU14\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    #print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU14 = df_AU14.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.319963</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.523067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.426265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.675452</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.511182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.306916</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.418321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.476664</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.267844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.331276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.703848</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.427269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.559221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.231357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.325595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.431424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.232149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.381732</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.377536</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.287261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.455488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.225308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.585734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.380039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.488119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.438960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.386491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.470888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.397470</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.306731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.522248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.124252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.451122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.524249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.379513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.351209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.369114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.322582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.392882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.421500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.299091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.308539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.389486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.516850</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.495562</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.532954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.510809</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.200407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.244860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.535935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.618097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.319963       0       0.262014      0\n",
       "1          303        0.523067       0       0.431689      0\n",
       "2          304        0.426265       0       0.272055      0\n",
       "3          372        0.675452       1       0.525029      1\n",
       "4          374        0.511182       1       0.450038      0\n",
       "5          375        0.306916       0       0.345473      0\n",
       "6          376        0.418321       0       0.405676      1\n",
       "7          377        0.476664       1       0.312424      1\n",
       "8          379        0.267844       0       0.331276      0\n",
       "9          380        0.703848       1       0.338716      1\n",
       "10         381        0.427269       0       0.441690      1\n",
       "11         382        0.153100       0       0.226980      0\n",
       "12         383        0.559221       1       0.596375      0\n",
       "13         385        0.231357       0       0.257899      0\n",
       "14         386        0.325595       0       0.280321      1\n",
       "15         388        0.431424       0       0.469421      1\n",
       "16         389        0.232149       0       0.268246      1\n",
       "17         390        0.381732       1       0.217548      0\n",
       "18         391        0.377536       0       0.405368      0\n",
       "19         392        0.287261       0       0.370545      0\n",
       "20         393        0.455488       0       0.604040      0\n",
       "21         395        0.225308       0       0.223609      0\n",
       "22         397        0.585734       0       0.738794      0\n",
       "23         400        0.380039       0       0.430632      0\n",
       "24         401        0.488119       0       0.587055      0\n",
       "25         402        0.438960       0       0.507109      1\n",
       "26         403        0.386491       0       0.339760      0\n",
       "27         404        0.470888       0       0.498882      0\n",
       "28         406        0.397470       0       0.368350      0\n",
       "29         409        0.306731       0       0.296781      1\n",
       "30         412        0.522248       0       0.801130      1\n",
       "31         413        0.124252       0       0.171341      1\n",
       "32         414        0.451122       0       0.594357      1\n",
       "33         415        0.524249       0       0.512673      0\n",
       "34         416        0.379513       0       0.528107      0\n",
       "35         417        0.351209       0       0.380970      0\n",
       "36         418        0.369114       0       0.393356      1\n",
       "37         419        0.322582       0       0.304086      0\n",
       "38         420        0.161468       0       0.186890      0\n",
       "39         422        0.392882       1       0.267769      1\n",
       "40         423        0.421500       0       0.453354      0\n",
       "41         425        0.299091       0       0.248173      0\n",
       "42         426        0.308539       0       0.334273      1\n",
       "43         427        0.389486       0       0.330293      0\n",
       "44         428        0.516850       0       0.779980      0\n",
       "45         429        0.495562       0       0.652392      0\n",
       "46         430        0.532954       0       0.841007      0\n",
       "47         433        0.348562       0       0.306340      1\n",
       "48         434        0.510809       1       0.243144      0\n",
       "49         436        0.200407       0       0.226239      0\n",
       "50         437        0.244860       0       0.181369      0\n",
       "51         439        0.535935       0       0.441612      0\n",
       "52         440        0.618097       1       0.620693      1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU14)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU14.ratio_no_total,df_AU14.portion,df_AU14.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
      "[[11  3]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        14\n",
      "           1       0.25      0.25      0.25         4\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.52      0.52      0.52        18\n",
      "weighted avg       0.67      0.67      0.67        18\n",
      "\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU15=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU15=data.AU15_r[data.AU15_r!=' 0']\n",
    "    ratio_AU15=temp_df_AU15.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU15\n",
    "    \n",
    "    temp_df_AU15=data.timestamp[data.AU15_r!=' 0']\n",
    "    AU15_st=0\n",
    "    AU15_et=0\n",
    "    AU15_t=-1\n",
    "    l_AU15=temp_df_AU15.tolist()\n",
    "    for j in range(1,len(l_AU15)):\n",
    "        time=float(l_AU15[j])\n",
    "        if time<=divide_time:\n",
    "            AU15_st+=1\n",
    "        else:\n",
    "            AU15_et+=1\n",
    "    if AU15_st>AU15_et:\n",
    "        AU15_t=0\n",
    "    else:\n",
    "        AU15_t=1\n",
    "    print(AU15_t) \n",
    "    d_newdf[\"portion\"]=AU15_t\n",
    "    \n",
    "    temp_df_AU15=data.frame[data.AU15_r!=' 0']\n",
    "    l_AU15=temp_df_AU15.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU15:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU15=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU15\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU15 = df_AU15.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.130752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.239802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.358017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.500760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.407512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.208188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.298476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.306359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.575809</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.158344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.330688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.068481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.364811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.188442</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.270539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.224983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.118697</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.223116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.131564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.559790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.266358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.309334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.343840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.165230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.295186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.284388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.178789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.321743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.093456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.205431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.383666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.263646</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.185702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.364891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.103310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.154532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.278472</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.321764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.186203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.085548</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.213841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.222075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.355437</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.398783</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.039248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.233129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.427585</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.405944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.130752       0       0.127867      0\n",
       "1          303        0.239802       0       0.139624      0\n",
       "2          304        0.358017       0       0.203600      0\n",
       "3          372        0.500760       1       0.223386      1\n",
       "4          374        0.407512       1       0.250942      0\n",
       "5          375        0.208188       0       0.183465      0\n",
       "6          376        0.298476       0       0.262144      1\n",
       "7          377        0.306359       1       0.158030      1\n",
       "8          379        0.079891       0       0.110153      0\n",
       "9          380        0.575809       1       0.175516      1\n",
       "10         381        0.158344       0       0.136349      1\n",
       "11         382        0.036637       0       0.095006      0\n",
       "12         383        0.330688       1       0.146131      0\n",
       "13         385        0.068481       0       0.123891      0\n",
       "14         386        0.364811       0       0.270248      1\n",
       "15         388        0.188442       0       0.168995      1\n",
       "16         389        0.131198       0       0.181718      1\n",
       "17         390        0.270539       1       0.130556      0\n",
       "18         391        0.224983       0       0.198997      0\n",
       "19         392        0.118697       0       0.155220      0\n",
       "20         393        0.223116       0       0.159766      0\n",
       "21         395        0.131564       0       0.159455      0\n",
       "22         397        0.559790       0       0.652949      0\n",
       "23         400        0.266358       0       0.250158      0\n",
       "24         401        0.309334       0       0.232693      0\n",
       "25         402        0.343840       0       0.325194      1\n",
       "26         403        0.165230       0       0.169279      0\n",
       "27         404        0.295186       0       0.184151      0\n",
       "28         406        0.284388       0       0.225176      0\n",
       "29         409        0.178789       0       0.209948      1\n",
       "30         412        0.321743       0       0.273424      1\n",
       "31         413        0.093456       0       0.142354      1\n",
       "32         414        0.205431       0       0.205597      1\n",
       "33         415        0.383666       0       0.357116      0\n",
       "34         416        0.263646       0       0.260312      0\n",
       "35         417        0.185702       0       0.168796      0\n",
       "36         418        0.364891       0       0.390074      1\n",
       "37         419        0.103310       0       0.141155      0\n",
       "38         420        0.154532       0       0.232707      0\n",
       "39         422        0.278472       1       0.163637      1\n",
       "40         423        0.321764       0       0.308482      0\n",
       "41         425        0.186203       0       0.155542      0\n",
       "42         426        0.085548       0       0.112057      1\n",
       "43         427        0.213841       0       0.187034      0\n",
       "44         428        0.222075       0       0.180269      0\n",
       "45         429        0.290598       0       0.221727      0\n",
       "46         430        0.355437       0       0.289850      0\n",
       "47         433        0.049011       0       0.103400      1\n",
       "48         434        0.398783       1       0.156114      0\n",
       "49         436        0.039248       0       0.095914      0\n",
       "50         437        0.233129       0       0.188087      0\n",
       "51         439        0.427585       1       0.266041      0\n",
       "52         440        0.405944       1       0.203904      1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1]\n",
      "[[ 4 10]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44        14\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.64      0.64      0.44        18\n",
      "weighted avg       0.84      0.44      0.44        18\n",
      "\n",
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU17=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU17=data.AU17_r[data.AU17_r!=' 0']\n",
    "    ratio_AU17=temp_df_AU17.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU17\n",
    "    \n",
    "    temp_df_AU17=data.timestamp[data.AU17_r!=' 0']\n",
    "    AU17_st=0\n",
    "    AU17_et=0\n",
    "    AU17_t=-1\n",
    "    l_AU17=temp_df_AU17.tolist()\n",
    "    for j in range(1,len(l_AU17)):\n",
    "        time=float(l_AU17[j])\n",
    "        if time<=divide_time:\n",
    "            AU17_st+=1\n",
    "        else:\n",
    "            AU17_et+=1\n",
    "    if AU17_st>AU17_et:\n",
    "        AU17_t=0\n",
    "    else:\n",
    "        AU17_t=1\n",
    "    print(AU17_t) \n",
    "    d_newdf[\"portion\"]=AU17_t\n",
    "    \n",
    "    temp_df_AU17=data.frame[data.AU17_r!=' 0']\n",
    "    l_AU17=temp_df_AU17.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU17:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU17=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU17\n",
    "    \n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU17 = df_AU17.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.233741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.496144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.217695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.516525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.238818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.132532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.197056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.331502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.062529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.588167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.165718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.452781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.207946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.204283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.145150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.337903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.088806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.272362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.143521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.367448</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.166590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.447303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.219640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.333746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.257569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.411691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.133882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.193893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.170623</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.450862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.034298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.183558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.279153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.363075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.252631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.263911</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.364370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.089335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.397668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.308501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.179761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.201394</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.041736</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.465352</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.077091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.160978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.451974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.373441</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.233741       0       0.239630      0\n",
       "1          303        0.496144       0       0.450181      0\n",
       "2          304        0.217695       0       0.197654      0\n",
       "3          372        0.516525       1       0.318990      1\n",
       "4          374        0.238818       1       0.197004      0\n",
       "5          375        0.132532       0       0.254409      0\n",
       "6          376        0.197056       0       0.244386      1\n",
       "7          377        0.331502       1       0.272450      1\n",
       "8          379        0.062529       0       0.126996      0\n",
       "9          380        0.588167       1       0.247223      1\n",
       "10         381        0.165718       0       0.266044      1\n",
       "11         382        0.099842       0       0.260827      0\n",
       "12         383        0.452781       1       0.332912      0\n",
       "13         385        0.015784       0       0.123134      0\n",
       "14         386        0.207946       0       0.265351      1\n",
       "15         388        0.204283       0       0.371542      1\n",
       "16         389        0.145150       0       0.336584      1\n",
       "17         390        0.337903       1       0.269987      0\n",
       "18         391        0.134715       0       0.259638      0\n",
       "19         392        0.088806       0       0.254509      0\n",
       "20         393        0.272362       0       0.343133      0\n",
       "21         395        0.143521       0       0.194792      0\n",
       "22         397        0.367448       0       0.574003      0\n",
       "23         400        0.166590       0       0.328455      0\n",
       "24         401        0.447303       0       0.496762      0\n",
       "25         402        0.219640       0       0.277291      1\n",
       "26         403        0.333746       0       0.360191      0\n",
       "27         404        0.257569       0       0.330131      0\n",
       "28         406        0.411691       0       0.486218      0\n",
       "29         409        0.133882       0       0.210115      1\n",
       "30         412        0.193893       0       0.391364      1\n",
       "31         413        0.236500       0       0.251919      1\n",
       "32         414        0.170623       0       0.201684      1\n",
       "33         415        0.450862       0       0.448902      0\n",
       "34         416        0.034298       0       0.204085      0\n",
       "35         417        0.183558       0       0.280126      0\n",
       "36         418        0.279153       0       0.312146      1\n",
       "37         419        0.363075       0       0.395119      0\n",
       "38         420        0.252631       0       0.340509      0\n",
       "39         422        0.263911       1       0.208110      1\n",
       "40         423        0.364370       0       0.480819      0\n",
       "41         425        0.089335       1       0.182400      0\n",
       "42         426        0.069831       0       0.319418      1\n",
       "43         427        0.397668       0       0.475933      0\n",
       "44         428        0.308501       0       0.440091      0\n",
       "45         429        0.179761       0       0.302568      0\n",
       "46         430        0.201394       0       0.260159      0\n",
       "47         433        0.041736       0       0.139970      1\n",
       "48         434        0.465352       1       0.284886      0\n",
       "49         436        0.077091       0       0.175963      0\n",
       "50         437        0.160978       0       0.229655      0\n",
       "51         439        0.451974       1       0.342195      0\n",
       "52         440        0.373441       1       0.266065      1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU20=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU20=data.AU20_r[data.AU20_r!=' 0']\n",
    "    ratio_AU20=temp_df_AU20.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU20\n",
    "    \n",
    "    temp_df_AU20=data.timestamp[data.AU20_r!=' 0']\n",
    "    AU20_st=0\n",
    "    AU20_et=0\n",
    "    AU20_t=-1\n",
    "    l_AU20=temp_df_AU20.tolist()\n",
    "    for j in range(1,len(l_AU20)):\n",
    "        time=float(l_AU20[j])\n",
    "        if time<=divide_time:\n",
    "            AU20_st+=1\n",
    "        else:\n",
    "            AU20_et+=1\n",
    "    if AU20_st>AU20_et:\n",
    "        AU20_t=0\n",
    "    else:\n",
    "        AU20_t=1\n",
    "    print(AU20_t) \n",
    "    d_newdf[\"portion\"]=AU20_t\n",
    "    \n",
    "    temp_df_AU20=data.frame[data.AU20_r!=' 0']\n",
    "    l_AU20=temp_df_AU20.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU20:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU20=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU20\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU20 = df_AU20.append(d_newdf, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.353336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.475512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.442875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.518440</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.467152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.393304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.366653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.425148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.218039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.133905</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.688574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.114643</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.493561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.175739</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.387578</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.351299</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.335898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.356820</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.303832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.160685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.335520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.227595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.460315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.427789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.290388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.335120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.307740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.377707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.217111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.382380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.201792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.262621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.456241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.257064</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.276071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.342340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.146605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.446803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.316543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.268741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.284496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.330604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.386292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.372969</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.230504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.228898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.236033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.442556</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.353336       0       0.223451      0\n",
       "1          303        0.475512       0       0.270485      0\n",
       "2          304        0.442875       0       0.235891      0\n",
       "3          372        0.518440       1       0.235479      1\n",
       "4          374        0.467152       1       0.238155      0\n",
       "5          375        0.393304       0       0.371912      0\n",
       "6          376        0.366653       0       0.261244      1\n",
       "7          377        0.425148       1       0.218039      1\n",
       "8          379        0.133905       0       0.104674      0\n",
       "9          380        0.688574       1       0.261115      1\n",
       "10         381        0.279114       0       0.192613      1\n",
       "11         382        0.114643       0       0.155243      0\n",
       "12         383        0.493561       1       0.261290      0\n",
       "13         385        0.175739       0       0.160067      0\n",
       "14         386        0.387578       0       0.242710      1\n",
       "15         388        0.351299       0       0.269351      1\n",
       "16         389        0.335898       0       0.349815      1\n",
       "17         390        0.356820       1       0.124406      0\n",
       "18         391        0.303832       0       0.228785      0\n",
       "19         392        0.160685       0       0.158491      0\n",
       "20         393        0.335520       0       0.247559      0\n",
       "21         395        0.227595       0       0.167176      0\n",
       "22         397        0.460315       0       0.479411      0\n",
       "23         400        0.427789       0       0.397589      0\n",
       "24         401        0.290388       0       0.171129      0\n",
       "25         402        0.335120       0       0.229575      1\n",
       "26         403        0.307740       0       0.226269      0\n",
       "27         404        0.496094       0       0.366368      0\n",
       "28         406        0.377707       0       0.233426      0\n",
       "29         409        0.217111       0       0.153218      1\n",
       "30         412        0.382380       0       0.327965      1\n",
       "31         413        0.201792       0       0.182286      1\n",
       "32         414        0.262621       0       0.228029      1\n",
       "33         415        0.456241       0       0.327818      0\n",
       "34         416        0.257064       0       0.216106      0\n",
       "35         417        0.276071       0       0.208034      0\n",
       "36         418        0.342340       0       0.310873      1\n",
       "37         419        0.285252       0       0.185475      0\n",
       "38         420        0.146605       0       0.135357      0\n",
       "39         422        0.446803       1       0.230607      1\n",
       "40         423        0.316543       0       0.268548      0\n",
       "41         425        0.362823       0       0.200799      0\n",
       "42         426        0.268741       0       0.234704      1\n",
       "43         427        0.284496       0       0.164646      0\n",
       "44         428        0.330604       0       0.256876      0\n",
       "45         429        0.386292       0       0.280348      0\n",
       "46         430        0.372969       0       0.277741      0\n",
       "47         433        0.230504       0       0.168728      1\n",
       "48         434        0.505556       1       0.201577      0\n",
       "49         436        0.228898       0       0.165561      0\n",
       "50         437        0.236033       0       0.150350      0\n",
       "51         439        0.442556       1       0.234450      0\n",
       "52         440        0.500035       1       0.249913      1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU25=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU25=data.AU25_r[data.AU25_r!=' 0']\n",
    "    ratio_AU25=temp_df_AU25.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU25\n",
    "    \n",
    "    temp_df_AU25=data.timestamp[data.AU25_r!=' 0']\n",
    "    AU25_st=0\n",
    "    AU25_et=0\n",
    "    AU25_t=-1\n",
    "    l_AU25=temp_df_AU25.tolist()\n",
    "    for j in range(1,len(l_AU25)):\n",
    "        time=float(l_AU25[j])\n",
    "        if time<=divide_time:\n",
    "            AU25_st+=1\n",
    "        else:\n",
    "            AU25_et+=1\n",
    "    if AU25_st>AU25_et:\n",
    "        AU25_t=0\n",
    "    else:\n",
    "        AU25_t=1\n",
    "    print(AU25_t) \n",
    "    d_newdf[\"portion\"]=AU25_t\n",
    "    \n",
    "    temp_df_AU25=data.frame[data.AU25_r!=' 0']\n",
    "    l_AU25=temp_df_AU25.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU25:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU25=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU25\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU25 = df_AU25.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.565698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.635493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.603213</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.701632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.489403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.574530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.765884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.432049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.791100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.646441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.611185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.714498</td>\n",
       "      <td>1</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.316493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.549477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.539301</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.458459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.598492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.535431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.459486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.603861</td>\n",
       "      <td>0</td>\n",
       "      <td>1.062844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.530567</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.679231</td>\n",
       "      <td>0</td>\n",
       "      <td>1.068327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.537520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.618524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.573940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.639368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.532945</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.620468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.486620</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.614772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.703509</td>\n",
       "      <td>0</td>\n",
       "      <td>1.246734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.537378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.474496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.638691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.609116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.659965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.615014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.624246</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.537950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.551902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.550360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.546002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.653769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.491312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.656649</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.545935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.331324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.564069</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.688833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.694322</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.565698       0       0.462819      0\n",
       "1          303        0.635493       0       0.441190      0\n",
       "2          304        0.603213       0       0.453371      0\n",
       "3          372        0.701632       1       0.611632      1\n",
       "4          374        0.718938       0       0.702621      0\n",
       "5          375        0.489403       0       0.375318      0\n",
       "6          376        0.574530       0       0.417268      1\n",
       "7          377        0.765884       0       0.706906      1\n",
       "8          379        0.432049       0       0.238360      0\n",
       "9          380        0.791100       1       0.642855      1\n",
       "10         381        0.646441       0       0.855803      1\n",
       "11         382        0.611185       0       0.507648      0\n",
       "12         383        0.714498       1       0.832751      0\n",
       "13         385        0.316493       0       0.193552      0\n",
       "14         386        0.549477       0       0.367963      1\n",
       "15         388        0.539301       0       0.455997      1\n",
       "16         389        0.458459       0       0.429098      1\n",
       "17         390        0.598492       1       0.371992      0\n",
       "18         391        0.535431       0       0.520942      0\n",
       "19         392        0.459486       0       0.459458      0\n",
       "20         393        0.603861       0       1.062844      0\n",
       "21         395        0.530567       0       0.456038      0\n",
       "22         397        0.679231       0       1.068327      0\n",
       "23         400        0.537520       0       0.453025      0\n",
       "24         401        0.618524       0       0.627145      0\n",
       "25         402        0.557000       0       0.637069      1\n",
       "26         403        0.573940       0       0.779146      0\n",
       "27         404        0.639368       0       0.692157      0\n",
       "28         406        0.532945       0       0.417566      0\n",
       "29         409        0.620468       0       0.647785      1\n",
       "30         412        0.486620       0       0.343966      1\n",
       "31         413        0.614772       0       0.597118      1\n",
       "32         414        0.567806       0       0.512800      1\n",
       "33         415        0.703509       0       1.246734      0\n",
       "34         416        0.537378       0       0.484822      0\n",
       "35         417        0.550863       0       0.535829      0\n",
       "36         418        0.474496       0       0.481763      1\n",
       "37         419        0.638691       0       0.705940      0\n",
       "38         420        0.609116       0       0.560392      0\n",
       "39         422        0.659965       1       0.666684      1\n",
       "40         423        0.615014       0       0.669918      0\n",
       "41         425        0.624246       0       0.440052      0\n",
       "42         426        0.537950       0       0.541835      1\n",
       "43         427        0.551902       0       0.456447      0\n",
       "44         428        0.550360       0       0.608929      0\n",
       "45         429        0.546002       0       0.510393      0\n",
       "46         430        0.653769       0       0.631577      0\n",
       "47         433        0.491312       0       0.533462      1\n",
       "48         434        0.656649       0       0.412952      0\n",
       "49         436        0.545935       0       0.331324      0\n",
       "50         437        0.564069       0       0.446915      0\n",
       "51         439        0.688833       0       0.635449      0\n",
       "52         440        0.694322       1       0.645899      1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "1\n",
      "[16]\n",
      "1\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU26=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU26=data.AU26_r[data.AU26_r!=' 0']\n",
    "    ratio_AU26=temp_df_AU26.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU26\n",
    "    \n",
    "    temp_df_AU26=data.timestamp[data.AU26_r!=' 0']\n",
    "    AU26_st=0\n",
    "    AU26_et=0\n",
    "    AU26_t=-1\n",
    "    l_AU26=temp_df_AU26.tolist()\n",
    "    for j in range(1,len(l_AU26)):\n",
    "        time=float(l_AU26[j])\n",
    "        if time<=divide_time:\n",
    "            AU26_st+=1\n",
    "        else:\n",
    "            AU26_et+=1\n",
    "    if AU26_st>AU26_et:\n",
    "        AU26_t=0\n",
    "    else:\n",
    "        AU26_t=1\n",
    "    print(AU26_t) \n",
    "    d_newdf[\"portion\"]=AU26_t\n",
    "    \n",
    "    temp_df_AU26=data.frame[data.AU26_r!=' 0']\n",
    "    l_AU26=temp_df_AU26.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU26:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU26=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU26\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU26 = df_AU26.append(d_newdf, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.095143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.083260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.381311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.214123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.107850</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.162968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.187644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.522580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.289324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.097564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.048989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.216072</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.107370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.111072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.059720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.324406</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.054510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.062280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.181363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.089024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.106534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.049199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.153262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.168324</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.231044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.074066</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.119160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.212170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.086888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.301581</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.200950</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.298536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.073582       0       0.420335      0\n",
       "1          303        0.095143       0       0.188160      0\n",
       "2          304        0.083260       0       0.172053      0\n",
       "3          372        0.381311       1       0.410784      1\n",
       "4          374        0.214123       1       0.183868      0\n",
       "5          375        0.107850       0       0.314053      0\n",
       "6          376        0.162968       0       0.250550      1\n",
       "7          377        0.187644       1       0.142516      1\n",
       "8          379        0.003925       0       0.118594      0\n",
       "9          380        0.522580       1       0.297906      1\n",
       "10         381        0.040665       1       0.235258      1\n",
       "11         382        0.011080       1       0.356400      0\n",
       "12         383        0.289324       1       0.254328      0\n",
       "13         385        0.097564       0       0.377453      0\n",
       "14         386        0.024819       0       0.157988      1\n",
       "15         388        0.015760       0       0.121415      1\n",
       "16         389        0.048989       0       0.352420      1\n",
       "17         390        0.216072       1       0.180344      0\n",
       "18         391        0.107370       0       0.451481      0\n",
       "19         392        0.111072       0       0.213036      0\n",
       "20         393        0.059720       0       0.243980      0\n",
       "21         395        0.011432       0       0.121939      0\n",
       "22         397        0.324406       0       1.049082      0\n",
       "23         400        0.054510       1       0.391140      0\n",
       "24         401        0.014343       0       0.147931      0\n",
       "25         402        0.062280       0       0.187725      1\n",
       "26         403        0.155029       0       0.291330      0\n",
       "27         404        0.181363       1       0.435182      0\n",
       "28         406        0.089024       0       0.349220      0\n",
       "29         409        0.023890       1       0.202400      1\n",
       "30         412        0.106534       0       0.235136      1\n",
       "31         413        0.009463       1       0.191812      1\n",
       "32         414        0.049199       0       0.228789      1\n",
       "33         415        0.153262       0       0.339172      0\n",
       "34         416        0.024059       0       0.161540      0\n",
       "35         417        0.040615       0       0.237160      0\n",
       "36         418        0.168324       0       0.518194      1\n",
       "37         419        0.002942       0       0.116286      0\n",
       "38         420        0.005474       0       0.308000      0\n",
       "39         422        0.231044       1       0.255976      1\n",
       "40         423        0.025469       0       0.169939      0\n",
       "41         425        0.074066       1       0.229333      0\n",
       "42         426        0.119160       0       0.274245      1\n",
       "43         427        0.014796       0       0.323231      0\n",
       "44         428        0.087372       0       0.293956      0\n",
       "45         429        0.212170       0       0.385063      0\n",
       "46         430        0.086888       0       0.297000      0\n",
       "47         433        0.018582       0       0.136935      1\n",
       "48         434        0.301581       1       0.318834      0\n",
       "49         436        0.007607       0       0.205765      0\n",
       "50         437        0.019735       0       0.375000      0\n",
       "51         439        0.200950       1       0.184071      0\n",
       "52         440        0.298536       1       0.216118      1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77        14\n",
      "           1       0.33      0.50      0.40         4\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.58      0.61      0.58        18\n",
      "weighted avg       0.72      0.67      0.69        18\n",
      "\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU23=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU231=data.AU23_c[data.AU23_c!=' -100']\n",
    "    temp_df_AU23=temp_df_AU231[temp_df_AU231!=' 0']\n",
    "    ratio_AU23=temp_df_AU23.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU23\n",
    "    \n",
    "    temp_df_AU23=data.timestamp[data.AU23_c!=' 0']\n",
    "    AU23_st=0\n",
    "    AU23_et=0\n",
    "    AU23_t=-1\n",
    "    l_AU23=temp_df_AU23.tolist()\n",
    "    for j in range(1,len(l_AU23)):\n",
    "        time=float(l_AU23[j])\n",
    "        if time<=divide_time:\n",
    "            AU23_st+=1\n",
    "        else:\n",
    "            AU23_et+=1\n",
    "    if AU23_st>AU23_et:\n",
    "        AU23_t=0\n",
    "    else:\n",
    "        AU23_t=1\n",
    "    print(AU23_t) \n",
    "    d_newdf[\"portion\"]=AU23_t\n",
    "    \n",
    "    temp_df_AU23=data.frame[data.AU23_c!=' 0']\n",
    "    l_AU23=temp_df_AU23.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU23:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU23=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU23\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU23 = df_AU23.append(d_newdf, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.628349</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.437056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.692948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.646894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.960266</td>\n",
       "      <td>0</td>\n",
       "      <td>3.478936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.795407</td>\n",
       "      <td>0</td>\n",
       "      <td>1.497551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.807169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0</td>\n",
       "      <td>26.700300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.931285</td>\n",
       "      <td>0</td>\n",
       "      <td>10.335815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.982926</td>\n",
       "      <td>0</td>\n",
       "      <td>37.433786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.978285</td>\n",
       "      <td>0</td>\n",
       "      <td>18.137250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.560706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.912379</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.975085</td>\n",
       "      <td>0</td>\n",
       "      <td>11.584875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.723332</td>\n",
       "      <td>0</td>\n",
       "      <td>1.439480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.656410</td>\n",
       "      <td>0</td>\n",
       "      <td>2.074370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0</td>\n",
       "      <td>9.105440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.831275</td>\n",
       "      <td>0</td>\n",
       "      <td>1.487764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.881354</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.576514</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.797587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.926756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.622629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.968853</td>\n",
       "      <td>0</td>\n",
       "      <td>10.294125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.552320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.417742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.622903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.860368</td>\n",
       "      <td>0</td>\n",
       "      <td>1.525014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>0</td>\n",
       "      <td>12.939385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.629988</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.347644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.294056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.389767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.868895</td>\n",
       "      <td>0</td>\n",
       "      <td>1.395391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.846793</td>\n",
       "      <td>0</td>\n",
       "      <td>2.030618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.543925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.940446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.917543</td>\n",
       "      <td>0</td>\n",
       "      <td>7.190364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.966876</td>\n",
       "      <td>0</td>\n",
       "      <td>16.067163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.716423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0</td>\n",
       "      <td>11.598424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.922894</td>\n",
       "      <td>0</td>\n",
       "      <td>3.065839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.398287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.907195</td>\n",
       "      <td>0</td>\n",
       "      <td>1.901941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.915606</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.964707</td>\n",
       "      <td>0</td>\n",
       "      <td>12.125953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0</td>\n",
       "      <td>2.524339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.610137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0</td>\n",
       "      <td>33.472560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.497795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.863907</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.628349       0       0.585157      0\n",
       "1          303        0.437056       0       0.242536      0\n",
       "2          304        0.692948       0       0.541332      0\n",
       "3          372        0.646894       1       0.478906      1\n",
       "4          374        0.960266       0       3.478936      0\n",
       "5          375        0.795407       0       1.497551      0\n",
       "6          376        0.807169       0       0.644824      1\n",
       "7          377        0.975334       0      26.700300      1\n",
       "8          379        0.931285       0      10.335815      0\n",
       "9          380        0.876471       1       0.879196      1\n",
       "10         381        0.982926       0      37.433786      1\n",
       "11         382        0.978285       0      18.137250      0\n",
       "12         383        0.560706       1       0.295791      0\n",
       "13         385        0.912379       0       1.465594      0\n",
       "14         386        0.975085       0      11.584875      1\n",
       "15         388        0.723332       0       1.439480      1\n",
       "16         389        0.656410       0       2.074370      1\n",
       "17         390        0.984400       0       9.105440      0\n",
       "18         391        0.831275       0       1.487764      0\n",
       "19         392        0.881354       0       1.049529      0\n",
       "20         393        0.576514       0       0.536648      0\n",
       "21         395        0.540238       0       0.300250      0\n",
       "22         397        0.797587       0       0.926756      0\n",
       "23         400        0.622629       0       0.607123      0\n",
       "24         401        0.968853       0      10.294125      0\n",
       "25         402        0.552320       0       0.417742      1\n",
       "26         403        0.717995       0       0.622903      0\n",
       "27         404        0.721854       0       0.695982      0\n",
       "28         406        0.860368       0       1.525014      0\n",
       "29         409        0.952736       0      12.939385      1\n",
       "30         412        0.629988       0       1.069929      1\n",
       "31         413        0.347644       0       0.294056      1\n",
       "32         414        0.389767       0       0.296798      1\n",
       "33         415        0.868895       0       1.395391      0\n",
       "34         416        0.846793       0       2.030618      0\n",
       "35         417        0.401452       0       0.403550      0\n",
       "36         418        0.543925       0       0.940446      1\n",
       "37         419        0.917543       0       7.190364      0\n",
       "38         420        0.966876       0      16.067163      0\n",
       "39         422        0.456568       1       0.274737      1\n",
       "40         423        0.716423       0       0.613513      0\n",
       "41         425        0.991803       0      11.598424      0\n",
       "42         426        0.922894       0       3.065839      1\n",
       "43         427        0.052686       0       0.296825      0\n",
       "44         428        0.398287       0       0.350172      0\n",
       "45         429        0.907195       0       1.901941      0\n",
       "46         430        0.915606       0       2.490472      0\n",
       "47         433        0.964707       0      12.125953      1\n",
       "48         434        0.855978       0       2.524339      0\n",
       "49         436        0.610137       0       0.340058      0\n",
       "50         437        0.953704       0      33.472560      0\n",
       "51         439        0.497795       1       0.297801      0\n",
       "52         440        0.863907       1       1.166492      1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "1\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "1\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "1\n",
      "[12]\n",
      "1\n",
      "[10]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "1\n",
      "[10]\n",
      "1\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "1\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU28=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU281=data.AU28_c[data.AU28_c!=' -100']\n",
    "    temp_df_AU28=temp_df_AU281[temp_df_AU281!=' 0']\n",
    "    ratio_AU28=temp_df_AU28.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU28  \n",
    "    \n",
    "    temp_df_AU28=data.timestamp[data.AU28_c!=' 0']\n",
    "    AU28_st=0\n",
    "    AU28_et=0\n",
    "    AU28_t=-1\n",
    "    l_AU28=temp_df_AU28.tolist()\n",
    "    for j in range(1,len(l_AU28)):\n",
    "        time=float(l_AU28[j])\n",
    "        if time<=divide_time:\n",
    "            AU28_st+=1\n",
    "        else:\n",
    "            AU28_et+=1\n",
    "    if AU28_st>AU28_et:\n",
    "        AU28_t=0\n",
    "    else:\n",
    "        AU28_t=1\n",
    "    print(AU28_t) \n",
    "    d_newdf[\"portion\"]=AU28_t\n",
    "    \n",
    "    temp_df_AU28=data.frame[data.AU28_c!=' 0']\n",
    "    l_AU28=temp_df_AU28.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU28:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU28=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU28\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU28 = df_AU28.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.050237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.408645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.039696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.302728</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.152723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.491857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.021570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.178034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.446737</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.828132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.679761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.202848</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.079940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.230550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>1</td>\n",
       "      <td>1.160467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.585274</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.023486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.465797</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.184650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.013236</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.126588</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.018870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>1</td>\n",
       "      <td>1.689188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.369599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.087880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.063653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.199276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.056170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.165819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.069434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.202091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.227944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.050237       0       0.445997      0\n",
       "1          303        0.408645       0       0.372116      0\n",
       "2          304        0.039696       0       0.232280      0\n",
       "3          372        0.302728       1       0.333621      1\n",
       "4          374        0.152723       1       0.491857      0\n",
       "5          375        0.021570       0       0.697349      0\n",
       "6          376        0.029539       0       0.236954      1\n",
       "7          377        0.178034       1       0.613067      1\n",
       "8          379        0.020289       1       0.435523      0\n",
       "9          380        0.446737       1       0.580759      1\n",
       "10         381        0.828132       0       1.679761      1\n",
       "11         382        0.008896       0       0.349800      0\n",
       "12         383        0.202848       1       0.435417      0\n",
       "13         385        0.000373       0       0.645000      0\n",
       "14         386        0.079940       0       0.280268      1\n",
       "15         388        0.230550       0       0.448871      1\n",
       "16         389        0.002588       1       1.160467      1\n",
       "17         390        0.585274       1       0.387616      0\n",
       "18         391        0.007743       0       0.754075      0\n",
       "19         392        0.003660       0       0.731077      0\n",
       "20         393        0.023486       0       0.725732      0\n",
       "21         395        0.465797       0       0.486336      0\n",
       "22         397        0.184650       0       0.375011      0\n",
       "23         400        0.013236       0       0.295443      0\n",
       "24         401        0.007671       0       0.234208      0\n",
       "25         402        0.013160       0       0.464517      1\n",
       "26         403        0.004985       0       0.388850      0\n",
       "27         404        0.126588       1       0.329871      0\n",
       "28         406        0.025396       0       0.289805      0\n",
       "29         409        0.006780       1       0.549857      1\n",
       "30         412        0.001673       1       0.426000      1\n",
       "31         413        0.000903       1       0.925500      1\n",
       "32         414        0.015237       1       0.425400      1\n",
       "33         415        0.018870       0       0.308000      0\n",
       "34         416        0.004273       1       1.689188      0\n",
       "35         417        0.369599       0       0.409778      0\n",
       "36         418        0.087880       1       0.571379      1\n",
       "37         419        0.007098       1       0.366837      0\n",
       "38         420        0.063653       0       0.209819      0\n",
       "39         422        0.199276       1       0.444896      1\n",
       "40         423        0.003146       0       0.519200      0\n",
       "41         425        0.056170       1       0.258789      0\n",
       "42         426        0.006341       1       0.366194      1\n",
       "43         427        0.165819       0       0.270324      0\n",
       "44         428        0.069434       0       0.631767      0\n",
       "45         429        0.003029       1       0.556500      0\n",
       "46         430        0.000880       0       0.605000      0\n",
       "47         433        0.001829       1       0.693000      1\n",
       "48         434        0.708874       0       0.593236      0\n",
       "49         436        0.003101       0       0.685235      0\n",
       "50         437        0.000039       0       0.590213      0\n",
       "51         439        0.202091       1       0.256333      0\n",
       "52         440        0.227944       1       0.780786      1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.22      1.00      0.36         4\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.11      0.50      0.18        18\n",
      "weighted avg       0.05      0.22      0.08        18\n",
      "\n",
      "0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AU45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[13]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[12]\n",
      "1\n",
      "[16]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[7]\n",
      "0\n",
      "[8]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[17]\n",
      "0\n",
      "[14]\n",
      "1\n",
      "[9]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[9]\n",
      "0\n",
      "[11]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[2]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[12]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[16]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[7]\n",
      "0\n",
      "[10]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[3]\n",
      "1\n",
      "[12]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[6]\n",
      "0\n",
      "[20]\n",
      "0\n",
      "[5]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[1]\n",
      "0\n",
      "[3]\n",
      "0\n",
      "[10]\n",
      "1\n",
      "[2]\n",
      "0\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[1]\n",
      "1\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "df_AU45=pd.DataFrame(columns=[\"participant\",\"ratio_no_total\",\"portion\",\"mean_duration\",\"target\"])\n",
    "for i in files:\n",
    "    d_newdf={}\n",
    "    data = pd.read_csv(path+i, sep=\",\", header=None)\n",
    "    data.columns = [\"frame\", \"timestamp\", \"confidence\", \"success\", \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\", \"AU20_r\", \"AU25_r\", \"AU26_r\",\"AU04_c\",\"AU12_c\", \"AU15_c\", \"AU23_c\", \"AU28_c\", \"AU45_c\"]\n",
    "    d_newdf[\"participant\"]=i[0:3]\n",
    "    \n",
    "    temp_df_AU451=data.AU45_c[data.AU45_c!=' -100']\n",
    "    temp_df_AU45=temp_df_AU451[temp_df_AU451!=' 0']\n",
    "    ratio_AU45=temp_df_AU45.count()/len(data)\n",
    "    d_newdf[\"ratio_no_total\"]=ratio_AU45\n",
    "    \n",
    "    temp_df_AU45=data.timestamp[data.AU45_c!=' 0']\n",
    "    AU45_st=0\n",
    "    AU45_et=0\n",
    "    AU45_t=-1\n",
    "    l_AU45=temp_df_AU45.tolist()\n",
    "    for j in range(1,len(l_AU45)):\n",
    "        time=float(l_AU45[j])\n",
    "        if time<=divide_time:\n",
    "            AU45_st+=1\n",
    "        else:\n",
    "            AU45_et+=1\n",
    "    if AU45_st>AU45_et:\n",
    "        AU45_t=0\n",
    "    else:\n",
    "        AU45_t=1\n",
    "    print(AU45_t) \n",
    "    d_newdf[\"portion\"]=AU45_t\n",
    "    \n",
    "    temp_df_AU45=data.frame[data.AU45_c!=' 0']\n",
    "    l_AU45=temp_df_AU45.tolist()[1:]\n",
    "    #print(\"for \"+i[0:3])\n",
    "    #print(\"frames:\")\n",
    "    #print(l_AU01)\n",
    "    dur=0\n",
    "    l_dur=[]\n",
    "    l_actdur=[]\n",
    "    for j in l_AU45:\n",
    "        j=int(j)\n",
    "        if l_dur:\n",
    "            if l_dur[-1]+1==j:\n",
    "                dur+=1\n",
    "                l_dur.append(j)\n",
    "            else:\n",
    "                l_actdur.append(dur)\n",
    "                l_dur=[]\n",
    "                dur=1\n",
    "        else:\n",
    "            l_dur.append(j)\n",
    "            dur+=1\n",
    "    #print(\"duration:\")\n",
    "    #print(l_actdur)\n",
    "    sum_dur=0\n",
    "    for j in l_actdur:\n",
    "        sum_dur+=j*0.033\n",
    "    mean_AU45=sum_dur/len(l_actdur)\n",
    "    d_newdf[\"mean_duration\"]=mean_AU45\n",
    "    \n",
    "    target_newdf=target.PHQ8_depression[target.participant==int(i[0:3])]\n",
    "    #target_newdf=list(target_newdf)\n",
    "    target_newdf=target_newdf.tolist()\n",
    "    print(target_newdf)\n",
    "    if target_newdf[0]<10:\n",
    "       # print(\"Hi\")\n",
    "        target_newdf[0]=0\n",
    "    else:\n",
    "        target_newdf[0]=1\n",
    "    d_newdf[\"target\"]=target_newdf[0]\n",
    "    df_AU45 = df_AU45.append(d_newdf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>ratio_no_total</th>\n",
       "      <th>portion</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302</td>\n",
       "      <td>0.395834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>0.371914</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>0.358017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.653302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>0.625155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375</td>\n",
       "      <td>0.337554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376</td>\n",
       "      <td>0.411530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377</td>\n",
       "      <td>0.680116</td>\n",
       "      <td>1</td>\n",
       "      <td>1.577642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>379</td>\n",
       "      <td>0.443192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.601314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>0.733294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>381</td>\n",
       "      <td>0.299186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>382</td>\n",
       "      <td>0.307412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>383</td>\n",
       "      <td>0.521071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>0.304002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>386</td>\n",
       "      <td>0.402841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>388</td>\n",
       "      <td>0.450393</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>389</td>\n",
       "      <td>0.416638</td>\n",
       "      <td>0</td>\n",
       "      <td>1.155260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>0.551273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>391</td>\n",
       "      <td>0.392287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>392</td>\n",
       "      <td>0.413074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.751765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>393</td>\n",
       "      <td>0.443269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>395</td>\n",
       "      <td>0.428952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>397</td>\n",
       "      <td>0.448671</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.352001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>401</td>\n",
       "      <td>0.248180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402</td>\n",
       "      <td>0.436280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>403</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>0.404558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>0.367872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>409</td>\n",
       "      <td>0.418499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>412</td>\n",
       "      <td>0.320809</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>413</td>\n",
       "      <td>0.450129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>414</td>\n",
       "      <td>0.497647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>415</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>416</td>\n",
       "      <td>0.422511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>417</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>418</td>\n",
       "      <td>0.333956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.721973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>419</td>\n",
       "      <td>0.419125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>420</td>\n",
       "      <td>0.252112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>422</td>\n",
       "      <td>0.570754</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>423</td>\n",
       "      <td>0.358379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>425</td>\n",
       "      <td>0.349632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>426</td>\n",
       "      <td>0.488660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>427</td>\n",
       "      <td>0.280444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>428</td>\n",
       "      <td>0.394027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>429</td>\n",
       "      <td>0.421450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>430</td>\n",
       "      <td>0.474674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>433</td>\n",
       "      <td>0.355047</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>434</td>\n",
       "      <td>0.489924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>436</td>\n",
       "      <td>0.172449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>437</td>\n",
       "      <td>0.219397</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>439</td>\n",
       "      <td>0.424939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.420015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>440</td>\n",
       "      <td>0.585028</td>\n",
       "      <td>1</td>\n",
       "      <td>1.049436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  ratio_no_total portion  mean_duration target\n",
       "0          302        0.395834       0       0.548476      0\n",
       "1          303        0.371914       0       0.376469      0\n",
       "2          304        0.358017       0       0.409341      0\n",
       "3          372        0.653302       1       0.826380      1\n",
       "4          374        0.625155       1       0.943025      0\n",
       "5          375        0.337554       0       0.725158      0\n",
       "6          376        0.411530       0       0.604341      1\n",
       "7          377        0.680116       1       1.577642      1\n",
       "8          379        0.443192       0       0.601314      0\n",
       "9          380        0.733294       1       0.588530      1\n",
       "10         381        0.299186       0       0.312917      1\n",
       "11         382        0.307412       0       0.415768      0\n",
       "12         383        0.521071       1       0.770152      0\n",
       "13         385        0.304002       0       0.318210      0\n",
       "14         386        0.402841       0       0.457321      1\n",
       "15         388        0.450393       0       0.888462      1\n",
       "16         389        0.416638       0       1.155260      1\n",
       "17         390        0.551273       1       0.660000      0\n",
       "18         391        0.392287       0       0.791238      0\n",
       "19         392        0.413074       0       0.751765      0\n",
       "20         393        0.443269       0       0.871381      0\n",
       "21         395        0.428952       0       0.583208      0\n",
       "22         397        0.448671       0       0.455603      0\n",
       "23         400        0.352001       0       0.525196      0\n",
       "24         401        0.248180       0       0.332846      0\n",
       "25         402        0.436280       0       0.777694      1\n",
       "26         403        0.384211       0       0.537450      0\n",
       "27         404        0.404558       0       0.585337      0\n",
       "28         406        0.367872       0       0.422745      0\n",
       "29         409        0.418499       0       0.327573      1\n",
       "30         412        0.320809       0       0.308897      1\n",
       "31         413        0.450129       0       0.814967      1\n",
       "32         414        0.497647       0       0.934938      1\n",
       "33         415        0.478227       0       0.745713      0\n",
       "34         416        0.422511       0       0.700740      0\n",
       "35         417        0.427287       0       0.682892      0\n",
       "36         418        0.333956       0       0.721973      1\n",
       "37         419        0.419125       0       0.531895      0\n",
       "38         420        0.252112       0       0.381048      0\n",
       "39         422        0.570754       1       0.569105      1\n",
       "40         423        0.358379       0       0.621453      0\n",
       "41         425        0.349632       1       0.514242      0\n",
       "42         426        0.488660       0       0.681080      1\n",
       "43         427        0.280444       0       0.285074      0\n",
       "44         428        0.394027       0       0.627915      0\n",
       "45         429        0.421450       0       0.414289      0\n",
       "46         430        0.474674       0       0.777526      0\n",
       "47         433        0.355047       0       0.465205      1\n",
       "48         434        0.489924       1       0.607286      0\n",
       "49         436        0.172449       0       0.182448      0\n",
       "50         437        0.219397       0       0.231453      0\n",
       "51         439        0.424939       1       0.420015      0\n",
       "52         440        0.585028       1       1.049436      1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AU45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(df_AU01)\n",
    "y=a[:,4]\n",
    "x = np.column_stack((df_AU01.ratio_no_total,df_AU01.portion,df_AU01.mean_duration))\n",
    "#print (x),(y)\n",
    "y=y.astype('int')\n",
    "#z=np.column_stack(df_AU01.portion)\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(x, y, z,linewidths=1, alpha=.7,edgecolor='k',s = 200)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.91      0.62      0.65        18\n",
      "weighted avg       0.86      0.83      0.79        18\n",
      "\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[[12  2]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.68      0.68      0.68        18\n",
      "weighted avg       0.78      0.78      0.78        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.67      0.73      0.67        18\n",
      "weighted avg       0.80      0.72      0.74        18\n",
      "\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred=nb.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.39      0.50      0.44        18\n",
      "weighted avg       0.60      0.78      0.68        18\n",
      "\n",
      "0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred=sgd.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
      "[[9 5]\n",
      " [2 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.55      0.57      0.54        18\n",
      "weighted avg       0.70      0.61      0.64        18\n",
      "\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
