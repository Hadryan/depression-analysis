{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Audio processing.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanditagoyal1997/depression-analysis/blob/sankhya/Audio_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yojC77Zr28lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "49ca6898-6c1a-4722-a2f3-b8b90c26cb13"
      },
      "source": [
        "%tensorflow_version 1.15.2\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy.io import wavfile as wav\n",
        "from scipy import signal\n",
        "from scipy.fftpack import fft,fftfreq\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
        "from tensorflow.python.keras import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1\n",
        "from keras.models import model_from_json\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LvpWPB3IfFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19816898-b1f4-46ef-9d76-44f61b457283"
      },
      "source": [
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zjcSCU128mj",
        "colab_type": "text"
      },
      "source": [
        "# generating spectogram images from audio data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Mh5odk28mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=os.listdir()\n",
        "\n",
        "for i in a:\n",
        "    w=wave.open(i,'rb')\n",
        "    frames = w.readframes(-1)\n",
        "    sound_info = pylab.fromstring(frames, 'Int16')\n",
        "    frame_rate = w.getframerate()\n",
        "    w.close()\n",
        "    pylab.figure(num=None, figsize=(513, 125))\n",
        "    pylab.subplot(111)\n",
        "    pylab.title('spectrogram of the audio file')\n",
        "    pylab.specgram(sound_info, Fs=frame_rate)\n",
        "    pylab.savefig('E:/final year project/Spectrogram/'+i[0:-3]+'spec.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Zqkg5A28mt",
        "colab_type": "text"
      },
      "source": [
        "# cnn model for the spectogram images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_HxhwRO4crG",
        "colab_type": "text"
      },
      "source": [
        "first we willl write a script to change the directory to the current folder and then we will read all the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ipvC1v4cDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "10086a3a-682c-49bc-deee-cd9f2da2cd52"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWvU5xsF4_MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir()\n",
        "os.chdir('gdrive')\n",
        "os.chdir('My Drive/final year project')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxjSj3EF5SR2",
        "colab_type": "text"
      },
      "source": [
        "now we will write a script to read all the spectogram images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh6iLez8-N2G",
        "colab_type": "text"
      },
      "source": [
        "the cell below is only for train split and here we take all the images which are in trail split csv\n",
        "this is later to be exculded when all the data has been acquired"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDtxPPjstSmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_1=pd.read_csv('train_split_Depression_AVEC2017.csv')\n",
        "df_11=df_1.rename(columns={'PHQ8_Binary':'PHQ_Binary'})\n",
        "df_2=pd.read_csv('full_test_split.csv')\n",
        "df_3=pd.read_csv('full_test_split.csv')\n",
        "df_4=pd.concat([df_11,df_2,df_3]).drop_duplicates().reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPiTpxELumT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3.shape,df_2.shape,df_1.shape,df_4.shape\n",
        "df_11.columns,df_2.columns,df_3.columns,df_4.columns\n",
        "df_4.PHQ_Binary.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVeI-4vR8mWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "388ed692-2bfb-4072-e625-29f593b0cf35"
      },
      "source": [
        "df=pd.read_csv('train_split_Depression_AVEC2017.csv')\n",
        "id=df_4['Participant_ID'].tolist()\n",
        "id=np.array(id)\n",
        "score=df['PHQ8_Binary'].tolist()\n",
        "score=np.array(score)\n",
        "f=os.listdir('spectogram_resize')\n",
        "temp=[]\n",
        "\n",
        "for i in f:\n",
        "  if len(id)==0:\n",
        "    break\n",
        "  elif int(i[0:3]) in id:\n",
        "    temp.append(i)\n",
        "len(temp) # to check all the values have been read or not"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8gEfsFX5Rb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arr=[]\n",
        "# for i in temp1:\n",
        "#     t=load_img('spectogram_test/'+i)\n",
        "#     x=img_to_array(t)\n",
        "# #     x = x.reshape((1,) + x.shape)\n",
        "#     arr.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF58VrrECkDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr=[]\n",
        "for i in temp:\n",
        "    t=load_img('spectogram_resize/'+i)\n",
        "    x=img_to_array(t)\n",
        "#     x = x.reshape((1,) + x.shape)\n",
        "    arr.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq1Fscwu6i0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b2117103-294e-44cb-fe52-7efb5b685a8e"
      },
      "source": [
        "X=np.array(arr)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 512, 512, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATpjiBvc6ebH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=df_4['PHQ_Binary'].tolist()\n",
        "Y=to_categorical(y,num_classes=2)\n",
        "num_classes=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-ezciZJqQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGXudID28mu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "530dcd67-7087-4127-a94c-3c3a1a2b91d4"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
        "y_train[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLSIhANN28nn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "fdf5ea53-eff9-4a63-be36-6e9da0e5bdd3"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3,strides=(1,1) , activation='relu', input_shape=(512,512,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Conv2D(64,  kernel_size=5,strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Conv2D(128,  kernel_size=7,strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,optimizer=tensorflow.keras.optimizers.Adadelta(),metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(),f1 ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKq2NYCgSPVF",
        "colab_type": "text"
      },
      "source": [
        "the next model is the one used in the project\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GqFMaKHdpwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3,strides=(1,1) , activation='relu', input_shape=(512,512,3),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(32,  kernel_size=3,strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
        "model.add(Conv2D(64,  kernel_size=5,strides=(1,1), activation='relu'))\n",
        "model.add(Conv2D(64,  kernel_size=5,strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
        "model.add(Conv2D(128,  kernel_size=5,strides=(1,1), activation='relu'))\n",
        "model.add(Conv2D(128,  kernel_size=5,strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,optimizer=tensorflow.keras.optimizers.Adadelta(),metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E95V-t28nw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "17af2070-1097-41e6-c75e-a054c729c547"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 510, 510, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 508, 508, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 253, 253, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 249, 249, 64)      51264     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 245, 245, 64)      102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 122, 122, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 118, 118, 128)     204928    \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 114, 114, 128)     409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 401408)            0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               205521408 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 206,563,618\n",
            "Trainable params: 206,563,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB0CVsgkS7gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file = open('audio.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"audio.h5\")\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# load_model.evaluate(X_test,y_test)\n",
        "score = loaded_model.evaluate(X_test,y_test, verbose=0)\n",
        "print(score)\n",
        "# loaded_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "VG7oCZ4h28n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train,y_train,validation_split=0.1 ,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ArhYWa28oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "665498c7-2c95-4310-fc11-4a16973ed748"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r16/16 [==============================] - 1s 48ms/sample - loss: 0.7175 - acc: 0.5625 - precision_2: 0.6132 - recall_2: 0.6132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7175301909446716, 0.5625, 0.6131805, 0.6131805]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyCS0nR4SXsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports for storing weights \n",
        "from keras.models import load_model\n",
        "from keras.utils import CustomObjectScope\n",
        "from keras.initializers import glorot_uniform\n",
        "import tensorflow as tf\n",
        "\n",
        "# saving the weights\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"audio.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"audio.h5\")\n",
        "\n",
        "# retrieving the weights\n",
        "\n",
        "json_file = open('audio.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"audio.h5\")\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "# load_model.evaluate(X_test,y_test)\n",
        "score = loaded_model.evaluate(X_test,y_test, verbose=0)\n",
        "print(score)\n",
        "# loaded_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}